{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Introduction \n",
    "GANs are comprised of both generator and discriminator models. The generator is responsible for generating new samples from the domain, and the discriminator is responsible for classifying whether samples are real or fake (generated). Importantly, the performance of the discriminator model is used to update both the model weights of the discriminator itself and the generator model. This means that the generator never actually sees examples from the domain and is adapted based on how well the discriminator performs.\n",
    "\n",
    "This is a complex type of model both to understand and to train.\n",
    "\n",
    "One approach to better understand the nature of GAN models and how they can be trained is to develop a model from scratch for a very simple task.\n",
    "\n",
    "A simple task that provides a good context for developing a simple GAN from scratch is a one-dimensional function. This is because both real and generated samples can be plotted and visually inspected to get an idea of what has been learned. A simple function also does not require sophisticated neural network models, meaning the specific generator and discriminator models used on the architecture can be easily understood.\n",
    "\n",
    "\n",
    "## This model can be divided into Six parts. \n",
    "\n",
    "Select a One-Dimensional Function\n",
    "Define a Discriminator Model\n",
    "Define a Generator Model\n",
    "Training the Generator Model\n",
    "Evaluating the Performance of the GAN\n",
    "Complete Example of Training the GAN\n",
    "\n",
    "\n",
    "*We are taking the function of y=x^2 for the sake of simplicity* \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrimanator Model \n",
    "\n",
    "The model must take a sample from our problem, such as a vector with two elements, and output a classification prediction as to whether the sample is real or fake.\n",
    "\n",
    "This is a binary classification problem.\n",
    "\n",
    "Inputs: Sample with two real values.\n",
    "Outputs: Binary classification, likelihood the sample is real (or fake).\n",
    "\n",
    "\n",
    "The problem is very simple, meaning that we donâ€™t need a complex neural network to model it.\n",
    "\n",
    "The discriminator model will have one hidden layer with 25 nodes and we will use the ReLU activation function and an appropriate weight initialization method called He weight initialization.\n",
    "\n",
    "The output layer will have one node for the binary classification using the sigmoid activation function.\n",
    "\n",
    "The model will minimize the binary cross entropy loss function, and the Adam version of stochastic gradient descent will be used because it is very effective.\n",
    "\n",
    "The define_discriminator() function below defines and returns the discriminator model. The function parameterizes the number of inputs to expect, which defaults to two."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could start training this model now with real examples with a class label of one and randomly generated samples with a class label of zero.\n",
    "\n",
    "There is no need to do this, but the elements we will develop will be useful later, and it helps to see that the discriminator is just a normal neural network model.\n",
    "\n",
    "First, we can update our generate_samples() function from the prediction section and call it generate_real_samples() and have it also return the output class labels for the real samples, specifically, an array of 1 values, where class=1 means real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n real samples with class labels\n",
    "def generate_real_samples(n):\n",
    "\t# generate inputs in [-0.5, 0.5]\n",
    "\tX1 = rand(n) - 0.5\n",
    "\t# generate outputs X^2\n",
    "\tX2 = X1 * X1\n",
    "\t# stack arrays\n",
    "\tX1 = X1.reshape(n, 1)\n",
    "\tX2 = X2.reshape(n, 1)\n",
    "\tX = hstack((X1, X2))\n",
    "\t# generate class labels\n",
    "\ty = ones((n, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create fake samples. The above code can recycled. \n",
    "Fake samples must not give correct result. Hence  we will generate random values in the range -1 and 1 for both elements of a sample. The output class label for all of these examples is 0.\n",
    "\n",
    "This function will act as our fake generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n fake samples with class labels\n",
    "def generate_fake_samples(n):\n",
    "\t# generate inputs in [-1, 1]\n",
    "\tX1 = -1 + rand(n) * 2\n",
    "\t# generate outputs in [-1, 1]\n",
    "\tX2 = -1 + rand(n) * 2\n",
    "\t# stack arrays\n",
    "\tX1 = X1.reshape(n, 1)\n",
    "\tX2 = X2.reshape(n, 1)\n",
    "\tX = hstack((X1, X2))\n",
    "\t# generate class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to train and evaluate the discriminator model.\n",
    "\n",
    "This can be achieved by manually enumerating the training epochs and for each epoch generating a half batch of real examples and a half batch of fake examples, and updating the model on each, e.g. one whole batch of examples. The train() function could be used, but in this case, we will use the train_on_batch() function directly.\n",
    "\n",
    "The model can then be evaluated on the generated examples and we can report the classification accuracy on the real and fake samples."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
